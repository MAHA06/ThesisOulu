{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Thesis.ipynb",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MAHA06/ThesisOulu/blob/master/Adversarials/Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "54pec7A464Ta"
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(‘/content/gdrive’)"
   ],
   "execution_count": 137,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4GzjWdjAfomN"
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms,datasets\n",
    "np.random.seed(42) \n",
    "torch.manual_seed(42)\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GsxBn-i6fmfw"
   },
   "source": [
    "train_batch,test_batch=128,128\n",
    "img_size=(28,28)\n",
    "num_classes=10\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.0,), (1.0,))])\n",
    "dataset = datasets.MNIST(root = './data', train=True, transform = transform, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "test_set = datasets.MNIST(root = './data', train=False, transform = transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=1,shuffle=True) \n",
    "val_loader = torch.utils.data.DataLoader(val_set,batch_size=1,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=1,shuffle=True)"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YDRayKODFRju"
   },
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "    self.dropout1 = nn.Dropout2d(0.25)\n",
    "    self.dropout2 = nn.Dropout2d(0.5)\n",
    "    self.fc1 = nn.Linear(9216, 128)\n",
    "    self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = self.dropout1(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.dropout2(x)\n",
    "    x = self.fc2(x)\n",
    "    output = F.softmax(x, dim=1)\n",
    "    return output\n",
    "\n",
    "\n"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aJMQz9fdFRpn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "284383dd-f05f-42f5-c439-7e616b243334"
   },
   "source": [
    "use_cuda=True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Using the device:\",device)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the device: cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gl-WshaZFRsF"
   },
   "source": [
    "def fitModel(model,optimizer,scheduler,criterion,device,train_loader,val_loader,epochs):\n",
    "  data_loader={'train':train_loader,'val':val_loader}\n",
    "  print(\"Starting to fit the model\")\n",
    "  train_error,test_error=[],[]\n",
    "  best_points=np.zeros(img_size+(num_classes,),dtype=float)\n",
    "  best_scores=np.full(num_classes,-np.inf)\n",
    "  print(best_scores[1])\n",
    "  for epc in range(epochs):\n",
    "    loss_epoch,val_loss_epoch=0,0\n",
    "    for phase in ('train','val'):\n",
    "      for i,data in enumerate(data_loader[phase]):\n",
    "        \n",
    "        input,label=data[0].to(device),data[1].to(device)\n",
    "        # print(input.shape)\n",
    "        out=model(input)\n",
    "        # print(out)\n",
    "        loss=criterion(out,label)\n",
    "        predict_label=torch.argmax(out,dim=1)\n",
    "        out=out.squeeze().detach().cpu().numpy()\n",
    "        if phase == 'train':\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          loss_epoch+=loss.item()\n",
    "          # print(predict_label.item(),label.item())\n",
    "          # print(out[predict_label.item()],best_scores[predict_label.item()])\n",
    "          # print(out)\n",
    "          if epc == epochs-1 and predict_label.item()==label.item() and out[predict_label.item()]>best_scores[predict_label.item()]:#if last epoch and the predicted label is correct\n",
    "            best_scores[predict_label.item()]=out[predict_label.item()]\n",
    "            best_points[:,:,predict_label]=input.squeeze().detach().cpu().numpy()\n",
    "            # print(label.item(),out[label.item()])\n",
    "            # print(\"The scores were updated:\",best_scores)\n",
    "        else:\n",
    "          val_loss_epoch+=loss.item()\n",
    "    scheduler.step(val_loss_epoch/len(val_loader))\n",
    "    print(\"Epoch : {} Train Loss : {} Eval Loss : {}\".format(epc+1,loss_epoch/len(train_loader),val_loss_epoch/len(val_loader)))\n",
    "    train_error.append(loss_epoch)\n",
    "    test_error.append(val_loss_epoch)\n",
    "  \n",
    "  return train_error,test_error,best_points,best_scores\n",
    "        \n",
    "          \n",
    "\n",
    "\n"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E2VlV-xmFRuk"
   },
   "source": [
    "model=Net().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
    "criterion = nn.NLLLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "\n",
    "###############\n"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "AWmhvKHDgpCZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "50c7027f-f4fb-499d-ba5c-9746695a15a3"
   },
   "source": [
    "## RUN THE TRAINING\n",
    "loss,val_loss,best_points,best_scores=fitModel(model,optimizer,scheduler,criterion,device,train_loader,val_loader,1)\n"
   ],
   "execution_count": 186,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Starting to fit the model\n",
      "-inf\n",
      "Epoch : 1 Train Loss : -0.842552869892936 Eval Loss : -0.9287422099167317\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "HAUXpIF_79an",
    "outputId": "4a668da4-5154-4c39-db1b-8882c563584a"
   },
   "source": [
    "print(best_points.shape)\n",
    "plt.imshow(best_points[:,:,3])\n",
    "v=torch.tensor(best_points[:,:,3].reshape(1,1,28,28),dtype=torch.float32)\n",
    "print(model(v.to(device)))\n",
    "print(torch.argmax(model(v.to(device))))\n",
    "print(best_scores)"
   ],
   "execution_count": 190,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "(28, 28, 10)\n",
      "tensor([[1.4239e-28, 1.1498e-22, 6.9919e-14, 1.0000e+00, 5.8801e-18, 5.2523e-21,\n",
      "         6.5902e-38, 1.8411e-14, 4.6206e-17, 7.8552e-15]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(3, device='cuda:0')\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R59id5I4pOEj"
   },
   "source": [
    "filename = './Models/model_MNIST'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "filename = './Models/model_MNIST_cpu'\n",
    "pickle.dump(model.cpu(), open(filename, 'wb'))"
   ],
   "execution_count": 193,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1M92hyHXqrVI"
   },
   "source": [
    "def deepfool(image, net, num_classes, overshoot, max_iter):\n",
    "\n",
    "    \"\"\"\n",
    "       :param image:\n",
    "       :param net: network (input: images, output: values of activation **BEFORE** softmax).\n",
    "       :param num_classes: num_classes (limits the number of classes to test against, by default = 10)\n",
    "       :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).\n",
    "       :param max_iter: maximum number of iterations for deepfool (default = 50)\n",
    "       :return: minimal perturbation that fools the classifier, number of iterations that it required, new estimated_label and perturbed image\n",
    "    \"\"\"\n",
    "\n",
    "    is_cuda = torch.cuda.is_available()\n",
    "    if is_cuda:\n",
    "        image = image.cuda()\n",
    "        net = net.cuda()\n",
    "\n",
    "    f_image = net.forward(Variable(image[None, :, :, :], requires_grad=True)).data.cpu().numpy().flatten()\n",
    "    I = f_image.argsort()[::-1]\n",
    "\n",
    "    I = I[0:num_classes]\n",
    "    label = I[0]\n",
    "\n",
    "    input_shape = image.cpu().numpy().shape\n",
    "    pert_image = copy.deepcopy(image)\n",
    "    w = np.zeros(input_shape)\n",
    "    r_tot = np.zeros(input_shape)\n",
    "\n",
    "    loop_i = 0\n",
    "\n",
    "    x = Variable(pert_image[None, :], requires_grad=True)\n",
    "    fs = net.forward(x)\n",
    "    k_i = label\n",
    "\n",
    "    while k_i == label and loop_i < max_iter:\n",
    "\n",
    "        pert = np.inf\n",
    "        fs[0, I[0]].backward(retain_graph=True)\n",
    "        grad_orig = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "        for k in range(1, num_classes):\n",
    "            zero_gradients(x)\n",
    "\n",
    "            fs[0, I[k]].backward(retain_graph=True)\n",
    "            cur_grad = x.grad.data.cpu().numpy().copy()\n",
    "\n",
    "            # set new w_k and new f_k\n",
    "            w_k = cur_grad - grad_orig\n",
    "            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()\n",
    "\n",
    "            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
    "\n",
    "            # determine which w_k to use\n",
    "            if pert_k < pert:\n",
    "                pert = pert_k\n",
    "                w = w_k\n",
    "\n",
    "        # compute r_i and r_tot\n",
    "        # Added 1e-4 for numerical stability\n",
    "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
    "        r_tot = np.float32(r_tot + r_i)\n",
    "\n",
    "        if is_cuda:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()\n",
    "        else:\n",
    "            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)\n",
    "\n",
    "        x = Variable(pert_image, requires_grad=True)\n",
    "       # print(image.shape)\n",
    "       # print(x.view(1,1,image.shape[0],-1).shape)\n",
    "        fs = net.forward(x.view(1,1,image.shape[1],-1))\n",
    "        k_i = np.argmax(fs.data.cpu().numpy().flatten())\n",
    "\n",
    "        loop_i += 1\n",
    "\n",
    "    return (1+overshoot)*r_tot, loop_i, label, k_i, pert_image\n",
    "def fgsm_attack(input,epsilon,data_grad):\n",
    "  pert_out = input + epsilon*data_grad.sign()\n",
    "  pert_out = torch.clamp(pert_out, 0, 1)\n",
    "  return pert_out\n",
    "\n",
    "def ifgsm_attack(input,epsilon,data_grad):\n",
    "  iter = 10\n",
    "  alpha = epsilon/iter\n",
    "  pert_out = input\n",
    "  for i in range(iter-1):\n",
    "    pert_out = pert_out + alpha*data_grad.sign()\n",
    "    pert_out = torch.clamp(pert_out, 0, 1)\n",
    "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
    "      break\n",
    "  return pert_out\n",
    "\n",
    "def mifgsm_attack(input,epsilon,data_grad):\n",
    "  iter=10\n",
    "  decay_factor=1.0\n",
    "  pert_out = input\n",
    "  alpha = epsilon/iter\n",
    "  g=0\n",
    "  for i in range(iter-1):\n",
    "    g = decay_factor*g + data_grad/torch.norm(data_grad,p=1)\n",
    "    pert_out = pert_out + alpha*torch.sign(g)\n",
    "    pert_out = torch.clamp(pert_out, 0, 1)\n",
    "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
    "      break\n",
    "  return pert_out"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j1wEKDumo2wC"
   },
   "source": [
    "def JacobianMatrix(model,input):\n",
    "  print(\"Input size \",input.shape)\n",
    "  number_of_piels=input.shape[0]*input.shape[1]\n",
    "  J = torch.zeros ((1, 784, 10))   # loop will fill in Jacobian\n",
    "  input.requires_grad = True\n",
    "  preds = model (input)\n",
    "  for  i in range (10):\n",
    "      grd = torch.zeros ((1, 10))   # same shape as preds\n",
    "      grd[0, i] = 1    # column of Jacobian to compute\n",
    "      preds.backward (gradient = grd, retain_graph = True)\n",
    "      J[:,:,i] = input.grad   # fill in one column of Jacobian\n",
    "      input.grad.zero_()   # .backward() accumulates gradients, so reset to zero\n",
    "def JSM_attack(model, input):\n",
    "  input.requires_grad=True"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "activation_in = {}\n",
    "activation_out={}\n",
    "def get_activation_input(name):\n",
    "    def hook(model, input, output):\n",
    "        activation_in[name] = input[0].data\n",
    "    return hook\n",
    "def get_activation_output(name):\n",
    "    def hook(model, input, output):\n",
    "        activation_out[name] = output.clone().detach()\n",
    "    return hook\n",
    "def nth_derivative(f, wrt, n):\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        grads = torch.autograd.grad(f, wrt, create_graph=True)[0]\n",
    "        f = grads.sum()\n",
    "\n",
    "    return grads\n",
    "def get_higher_gradients(model,input,label, rank=3):\n",
    "  grads=[1,2,3]\n",
    "  optimizer.zero_grad()\n",
    "  input.requires_grad=True\n",
    "  outs=model(input)\n",
    "  pred=torch.zeros(num_classes)\n",
    "  pred[label.item()]=1\n",
    "  l=criterion(outs,label)\n",
    "  aux=torch.autograd.grad(l,input,retain_graph=True,create_graph=True)[0]\n",
    "  grads.append(aux.reshape(1,-1))\n",
    "  for r in range(2,rank+1):\n",
    "    aux=torch.autograd.grad(aux.sum(),input,create_graph=True)[0]\n",
    "    grads.append(aux.reshape(1,-1))\n",
    "  return grads\n",
    "def check_taylor_prediction(model,input,marker_images,perturbed_label):\n",
    "  plt.imshow(input.squeeze().detach().cpu().numpy())\n",
    "  # grads=get_higher_gradients(model,input,true_label)\n",
    "\n",
    "  # grads=get_higher_gradients(model,input,perturbed_label)\n",
    "  layer_grads=get_layer_gradients(model,input,perturbed_label,\"conv2\")\n",
    "  input=input.reshape(-1,1)\n",
    "  # marker_image=marker_images[:,:,true_label.item()].reshape(-1,1)\n",
    "  # marker_image=torch.tensor(marker_image,dtype=torch.float32)\n",
    "  # total=1.+torch.mm(grads[0],(input-marker_image))+torch.mm(grads[1],torch.pow((input-marker_image),2))/2\n",
    "  # total=1.+torch.mm(grads[0],(input-marker_image))+torch.mm(grads[1],torch.pow((input-marker_image),2))/2\n",
    "  marker_image1=marker_images[:,:,perturbed_label.item()].reshape(-1,1)\n",
    "  marker_image1=torch.tensor(marker_image1,dtype=torch.float32)\n",
    "  total1=torch.mm(layer_grads[0],(input-marker_image1))+torch.mm(layer_grads[1],torch.pow((input-marker_image1),2))/2\n",
    "\n",
    "  return total1.item()\n",
    "def get_layer_gradients(model,input,label,l_name, rank=3):\n",
    "  grads=[]\n",
    "  optimizer.zero_grad()\n",
    "  input.requires_grad=True\n",
    "  outs=model(input)\n",
    "  pred=torch.zeros(num_classes)\n",
    "  pred[label.item()]=1\n",
    "  l=criterion(outs,label)\n",
    "  # layer_input_data=activation_in[l_name]\n",
    "  # layer_input_data.requires_grad=True\n",
    "  layer_input_data=0\n",
    "  # aux=torch.autograd.grad(l,layer_input_data,retain_graph=True,create_graph=True)[0]\n",
    "  # grads.append(aux.reshape(1,-1))\n",
    "  # for r in range(2,rank+1):\n",
    "  #   aux=torch.autograd.grad(aux.sum(),layer_input_data,create_graph=True)[0]\n",
    "  #   grads.append(aux.reshape(1,-1))\n",
    "  return grads\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "filename = './model_MNIST_cpu.mf'\n",
    "model= pickle.load(open(filename, 'rb'))\n",
    "filename = './scores.mf'\n",
    "\n",
    "best_fits=pickle.load(open(filename,'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h3al_hO_mqKn",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "outputId": "34d3380b-4047-4f3b-ca67-e61fc63c6440",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "def testModel(model,criterion,device,test_loader,attack):\n",
    "  count=0\n",
    "  totals=0\n",
    "  fooled=0\n",
    "  for data,labels in test_loader:\n",
    "    data,labels=data.to(device),labels.to(device)\n",
    "    data.requires_grad=True\n",
    "    outs=model(data)\n",
    "    true_preds=torch.argmax(outs,dim=1)\n",
    "    if true_preds!=labels:\n",
    "      continue\n",
    "    epsilon=0.1\n",
    "    true_loss=criterion(outs,labels)\n",
    "    true_loss.backward()\n",
    "    data_grad=data.grad.data\n",
    "    if attack == \"fgsm\":\n",
    "      perturbed_data = fgsm_attack(data,epsilon,data_grad)\n",
    "    elif attack == \"ifgsm\":\n",
    "      perturbed_data = ifgsm_attack(data,epsilon,data_grad)\n",
    "    elif attack == \"mifgsm\":\n",
    "      perturbed_data = mifgsm_attack(data,epsilon,data_grad)\n",
    "    elif attack == \"jacobian\":\n",
    "      print(\"Implement the jacobian\")\n",
    "    p_out=model(perturbed_data)\n",
    "    perturb_label=torch.argmax(p_out,dim=1)\n",
    "    # print(perturb_label.item())\n",
    "\n",
    "    if perturb_label!=labels:\n",
    "      totals+=1\n",
    "      # print(\"Trying to determine for the true class:\",labels.item(),\" which was labeled as:\",perturb_label.item())\n",
    "      x=range(0,num_classes)\n",
    "      x=[check_taylor_prediction(model,data,best_fits['b_p'],torch.tensor(lab).reshape(1)) for lab in x ]\n",
    "      winner=np.argmax(x)\n",
    "      if winner == true_preds.item():\n",
    "        fooled+=1\n",
    "      if winner == labels.item():\n",
    "        count+=1\n",
    "      # r=check_taylor_prediction(model,data,best_fits['b_p'],perturb_label)\n",
    "      print(\"Total of :\",count/totals)\n",
    "      print(\"Fooled :\",fooled/totals)\n",
    "# conv2\n",
    "model.conv2.register_forward_hook(get_activation_input('conv2'))\n",
    "\n",
    "# model.conv2.register_forward_hook(get_activation_output('conv2'))\n",
    "testModel(model,criterion,'cpu',test_loader,\"ifgsm\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": 101,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-101-6676840c6671>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[0;31m# model.conv2.register_forward_hook(get_activation_output('conv2'))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m \u001B[0mtestModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mcriterion\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'cpu'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtest_loader\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\"ifgsm\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-101-6676840c6671>\u001B[0m in \u001B[0;36mtestModel\u001B[0;34m(model, criterion, device, test_loader, attack)\u001B[0m\n\u001B[1;32m     33\u001B[0m       \u001B[0;31m# print(\"Trying to determine for the true class:\",labels.item(),\" which was labeled as:\",perturb_label.item())\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m       \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m       \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcheck_taylor_prediction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mbest_fits\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'b_p'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlab\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mlab\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m       \u001B[0mwinner\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mwinner\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mtrue_preds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-101-6676840c6671>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     33\u001B[0m       \u001B[0;31m# print(\"Trying to determine for the true class:\",labels.item(),\" which was labeled as:\",perturb_label.item())\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m       \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m       \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcheck_taylor_prediction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mbest_fits\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'b_p'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlab\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mlab\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx\u001B[0m \u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m       \u001B[0mwinner\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mwinner\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mtrue_preds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-91-4356c70c3ed1>\u001B[0m in \u001B[0;36mcheck_taylor_prediction\u001B[0;34m(model, input, marker_images, perturbed_label)\u001B[0m\n\u001B[1;32m     45\u001B[0m   \u001B[0mmarker_image1\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmarker_images\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mperturbed_label\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m   \u001B[0mmarker_image1\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmarker_image1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m   \u001B[0mtotal1\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayer_grads\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mmarker_image1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayer_grads\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mmarker_image1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mtotal1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  }
 ]
}